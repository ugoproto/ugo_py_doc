<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Ugo Sparks">
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Intro to data.world in Python - ugo_py_doc</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Intro to data.world in Python";
    var mkdocs_page_input_path = "Intro to data.world in Python.md";
    var mkdocs_page_url = "/Intro to data.world in Python/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-93008985-2', 'mkdocs.org');
      ga('send', 'pageview');
  </script>
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> ugo_py_doc</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Basics & More</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../Py_CS/">Python Cheat Sheets</a>
                </li>
                <li class="">
                    
    <a class="" href="../Python_Preliminaries/">Python Preliminaries</a>
                </li>
                <li class="">
                    
    <a class="" href="../Python_Nice_to_Have/">Python Nice to Have</a>
                </li>
                <li class="">
                    
    <a class="" href="../Freeze_the_Code/">Freeze the Code</a>
                </li>
                <li class="">
                    
    <a class="" href="../Decorators/">Decorators</a>
                </li>
                <li class="">
                    
    <a class="" href="../Write_Better_Python/">Write Better Python with PEP</a>
                </li>
                <li class="">
                    
    <a class="" href="../Regex/">Regular Expressions (REGEX)</a>
                </li>
                <li class="">
                    
    <a class="" href="../Databases/">Databases</a>
                </li>
                <li class="">
                    
    <a class="" href="../Datetime/">Datetime</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">SciPy Stack</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../Scipy_CS/">Scipy Stack Cheat Sheets</a>
                </li>
                <li class="">
                    
    <a class="" href="../JN_CS/">Jupyter Notebook Cheat Sheets</a>
                </li>
                <li class="">
                    
    <a class="" href="../Scientific Python (the SciPy Stack)/">Scientific Python (the SciPy Stack)</a>
                </li>
                <li class="">
                    
    <a class="" href="../Importing Data into Python/">Importing Data into Python</a>
                </li>
                <li class="">
                    
    <a class="" href="../Python for Data Science/">Python for Data Science</a>
                </li>
                <li class="">
                    
    <a class="" href="../Tidy_Data_in_Python/">Tidy Data in Python</a>
                </li>
                <li class="">
                    
    <a class="" href="../Lists/">Lists</a>
                </li>
                <li class="">
                    
    <a class="" href="../IPython Notebook/">IPython Notebook, Collection</a>
                </li>
                <li class="">
                    
    <a class="" href="../Python Numpy Arrays/">Python Numpy Arrays</a>
                </li>
                <li class="">
                    
    <a class="" href="../Vectors and Arrays (Linear Algebra)/">Vectors and Arrays (Linear Algebra)</a>
                </li>
                <li class="">
                    
    <a class="" href="../Matplotlib, Python Plotting/">Matplotlib, Python Plotting</a>
                </li>
                <li class="">
                    
    <a class="" href="../Viewing+3D+Volumetric+Data+With+Matplotlib/">Viewing 3D Volumetric Data With Matplotlib</a>
                </li>
                <li class="">
                    
    <a class="" href="../Seaborn, Python Statistical Data Visualization Library/">Seaborn, Python's Statistical Data Visualization Library</a>
                </li>
                <li class="">
                    
    <a class="" href="../Pandas+DataFrames/">Pandas DataFrames</a>
                </li>
                <li class="">
                    
    <a class="" href="../Write Idiomatic Pandas Code/">Write Idiomatic Pandas Code</a>
                </li>
                <li class="">
                    
    <a class="" href="../Exploratory Data Analysis/">Exploratory Data Analysis</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">Intro to data.world in Python</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#working-with-datasets">Working with Datasets</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#import-a-dataset">Import a Dataset</a></li>
        
            <li><a class="toctree-l4" href="#working-with-datasets_1">Working with Datasets</a></li>
        
            <li><a class="toctree-l4" href="#reading-the-metadata">Reading the metadata</a></li>
        
            <li><a class="toctree-l4" href="#accessing-the-data">Accessing the data</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#working-with-multiple-datasets">Working with multiple datasets</a></li>
    

    <li class="toctree-l3"><a href="#querying-with-dataworld">Querying with data.world</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#sql-querying-a-table">SQL: Querying a table</a></li>
        
            <li><a class="toctree-l4" href="#sql-query-multiple-tables-join">SQL: Query multiple tables (join)</a></li>
        
            <li><a class="toctree-l4" href="#sparql-querying-linked-data">SPARQL: Querying linked data</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#wrap-up">Wrap up</a></li>
    

    <li class="toctree-l3"><a href="#advanced-sdk-functionality">Advanced SDK Functionality</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#open-the-api">Open the API</a></li>
        
            <li><a class="toctree-l4" href="#create-a-dataset-using-create_dataset-method">Create a dataset using create_dataset method</a></li>
        
            <li><a class="toctree-l4" href="#write-a-dataframe-to-a-local-file-and-upload-to-dataset">Write a dataframe to a local file and upload to dataset</a></li>
        
            <li><a class="toctree-l4" href="#update-dataset">Update dataset</a></li>
        
        </ul>
    

    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../Python+And+Excel/">Python and Excel</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Courses</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../Apprenez a programmer en Python/">Apprenez à programmer en Python</a>
                </li>
                <li class="">
                    
    <a class="" href="../Codecademy Python/">Codecademy Python</a>
                </li>
                <li class="">
                    
    <a class="" href="../Learn Python the Hard Way/">Learn Python the Hard Way</a>
                </li>
                <li class="">
                    
    <a class="" href="../Python Code Snippets/">Python Code Snippets</a>
                </li>
                <li class="">
                    
    <a class="" href="../Introduction to Python/">Introduction to Python</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Manuals</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../Automate the Boring Stuff with Python/">Automate the Boring Stuff with Python</a>
                </li>
                <li class="">
                    
    <a class="" href="../Real_Python/">Real Python</a>
                </li>
                <li class="">
                    
    <a class="" href="../Managing Your Biological Data with Python/">Managing Your Biological Data with Python</a>
                </li>
                <li class="">
                    
    <a class="" href="../Python for Education/">Python for Education</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">ugo_py_doc</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>SciPy Stack &raquo;</li>
        
      
    
    <li>Intro to data.world in Python</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <div class="toc"><span class="toctitle">CONTENT</span><ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#working-with-datasets">Working with Datasets</a><ul>
<li><a href="#import-a-dataset">Import a Dataset</a></li>
<li><a href="#working-with-datasets_1">Working with Datasets</a></li>
<li><a href="#reading-the-metadata">Reading the metadata</a></li>
<li><a href="#accessing-the-data">Accessing the data</a></li>
</ul>
</li>
<li><a href="#working-with-multiple-datasets">Working with multiple datasets</a></li>
<li><a href="#querying-with-dataworld">Querying with data.world</a><ul>
<li><a href="#sql-querying-a-table">SQL: Querying a table</a></li>
<li><a href="#sql-query-multiple-tables-join">SQL: Query multiple tables (join)</a></li>
<li><a href="#sparql-querying-linked-data">SPARQL: Querying linked data</a></li>
</ul>
</li>
<li><a href="#wrap-up">Wrap up</a></li>
<li><a href="#advanced-sdk-functionality">Advanced SDK Functionality</a><ul>
<li><a href="#open-the-api">Open the API</a></li>
<li><a href="#create-a-dataset-using-create_dataset-method">Create a dataset using create_dataset method</a></li>
<li><a href="#write-a-dataframe-to-a-local-file-and-upload-to-dataset">Write a dataframe to a local file and upload to dataset</a></li>
<li><a href="#update-dataset">Update dataset</a></li>
</ul>
</li>
</ul>
</div>
<hr />
<p><strong>Foreword</strong></p>
<p>Code snippets and excerpts from the course. Python 3. From DataCamp.</p>
<hr />
<h3 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h3>
<p>Open data is at the heart of <a href="https://data.world/integrations/python">data.world</a>. </p>
<p>Open an account, log in, find a dataset, download it or copy URL or integrate data.world with Python/R/Tableau by installing dw in the terminal. In Python for example.</p>
<p><code>pip install datadotworld[pandas]</code> or <code>conda install datadotworld-py</code></p>
<p>then,</p>
<p><code>dw configure</code></p>
<p>Pull the API token from the account and enter it.</p>
<p>There are similar procedures for R and Tableau. Everything is documented on the website (when trying to download any dataset, more options appear for Python/R/Tableau).</p>
<p>Option 1: use the data.world Jupyter Notebook template as a way to jump-start a project with Python.</p>
<p>Option 2:</p>
<pre><code class="python">%pylab inline
import pandas as pd
import os

# Import the datadotworld module as dw
import datadotworld as dw
</code></pre>

<pre><code>Populating the interactive namespace from numpy and matplotlib
</code></pre>
<h3 id="working-with-datasets">Working with Datasets<a class="headerlink" href="#working-with-datasets" title="Permanent link">&para;</a></h3>
<h4 id="import-a-dataset">Import a Dataset<a class="headerlink" href="#import-a-dataset" title="Permanent link">&para;</a></h4>
<p>Once the module is loaded, there are two ways to import a dataset.</p>
<pre><code class="python"># First
# Import the city council votes dataset
dataset = dw.load_dataset('stephen-hoover/chicago-city-council-votes')
</code></pre>

<p>The dataset is now in the cache.</p>
<pre><code class="python"># Second
# Import the city council votes dataset
dataset = dw.load_dataset('https://data.world/stephen-hoover/chicago-city-council-votes')
</code></pre>

<h4 id="working-with-datasets_1">Working with Datasets<a class="headerlink" href="#working-with-datasets_1" title="Permanent link">&para;</a></h4>
<p>From the beginning.</p>
<pre><code class="python"># Import the datadotworld module as dw
import datadotworld as dw
# Import the Pretty Print module
import pprint as pp
</code></pre>

<pre><code class="python"># Import the city council votes dataset
dataset = dw.load_dataset('https://data.world/stephen-hoover/chicago-city-council-votes')

# Use describe() 
# Review all the metadata that is downloaded with the dataset
# Print it to the screen using pp.pprint()
pp.pprint(dataset.describe())
</code></pre>

<pre><code>{'description': 'Chicago city council voting records from May 2006 to March '
                '2017\n'
                '\n'
                '# About this project\n'
                'This dataset aims to increase transparency into the Chicago '
                "city government by publishing each Alderman's voting record "
                'in an easily machine-readable format. These data come from '
                'pdfs [published by the Office of the City '
                'Clerk](http://www.chicityclerk.com/legislation-records/journals-and-reports/council-meeting-reports).\n'
                '\n'
                'This work was done as part of the Data for Democracy '
                '["Chicago '
                'Lobbyists"](https://data.world/lilianhj/chicago-lobbyists) '
                'project.\n'
                '\n'
                'The code which produced these data is at '
                'https://github.com/stephen-hoover/data-processing/blob/master/scraping/Scrape%20Chicago%20City%20Clerk%20Website.ipynb '
                '.\n'
                '\n'
                '# Still to-do\n'
                'It would be useful to include more information about each '
                'measure -- sponsors, full text, and subject tags would be '
                'particularly good to have.\n'
                '\n'
                'Aldermen names in the voting records are not fully '
                'standardized yet. Ideally the same person would always have '
                'exactly the same string.\n'
                '\n'
                '# External resources\n'
                '[City council meeting '
                'reports](http://www.chicityclerk.com/legislation-records/journals-and-reports/council-meeting-reports)\n'
                '\n'
                '[Chicago Councilmatic](https://chicago.councilmatic.org)\n'
                '\n'
                '[City of Chicago Legislative Information '
                'Center](https://chicago.legistar.com)',
 'homepage': 'https://data.world/stephen-hoover/chicago-city-council-votes',
 'keywords': ['chicago', 'government'],
 'license': 'Public Domain',
 'name': 'stephen-hoover_chicago-city-council-votes',
 'resources': [{'format': 'csv',
                'name': 'alderman_votes',
                'path': 'data/alderman_votes.csv'},
               {'format': 'csv',
                'name': 'legislation_titles',
                'path': 'data/legislation_titles.csv'},
               {'bytes': 428918,
                'format': 'csv',
                'keywords': ['clean data'],
                'mediatype': 'text/csv',
                'name': 'original/alderman_votes.csv',
                'path': 'original/alderman_votes.csv'},
               {'bytes': 29658,
                'description': 'These are titles for each of the issues in the '
                               'alderman_votes.csv document. Join on "Record".',
                'format': 'csv',
                'keywords': ['clean data'],
                'mediatype': 'text/csv',
                'name': 'original/legislation_titles.csv',
                'path': 'original/legislation_titles.csv'}],
 'title': 'Chicago City Council Votes'}
</code></pre>
<pre><code class="python"># Use describe() again
# Get a description of a specific resource: alderman_votes
# Print it to the screen
pp.pprint(dataset.describe('alderman_votes'))
</code></pre>

<pre><code>{'format': 'csv',
 'name': 'alderman_votes',
 'path': 'data/alderman_votes.csv',
 'schema': {'fields': [{'description': 'Note that some entries contain a full '
                                       'name and others only have a last name.',
                        'name': 'alderman',
                        'rdfType': 'http://www.w3.org/2001/XMLSchema#string',
                        'title': 'Alderman',
                        'type': 'string'},
                       {'description': 'VOTE KEY: Y=Yes; N=No; A=Absent; '
                                       'NV=Not Voting;  E=Excused; V=Vacant '
                                       'R=Recusals from voting',
                        'name': 'vote',
                        'rdfType': 'http://www.w3.org/2001/XMLSchema#string',
                        'title': 'Vote',
                        'type': 'string'},
                       {'name': 'ward',
                        'rdfType': 'http://www.w3.org/2001/XMLSchema#integer',
                        'title': 'Ward',
                        'type': 'integer'},
                       {'description': 'YYYY-MM-DD',
                        'name': 'date',
                        'rdfType': 'http://www.w3.org/2001/XMLSchema#date',
                        'title': 'Date',
                        'type': 'date'},
                       {'name': 'record',
                        'rdfType': 'http://www.w3.org/2001/XMLSchema#string',
                        'title': 'Record',
                        'type': 'string'}]}}
</code></pre>
<h4 id="reading-the-metadata">Reading the metadata<a class="headerlink" href="#reading-the-metadata" title="Permanent link">&para;</a></h4>
<p>All fields begin with <code>{</code>. The <code>alderman_votes</code> variable has 5 fields.</p>
<h4 id="accessing-the-data">Accessing the data<a class="headerlink" href="#accessing-the-data" title="Permanent link">&para;</a></h4>
<p>We have access to three properties: <code>raw_data</code>, <code>tables</code>, and <code>dataframes</code>. Each of these returns a dictionary of values, just in different formats: <code>bytes</code>, <code>list</code> and <code>pandas.DataFrame</code> objects.</p>
<pre><code class="python"># Use the dataframes property
# Assign the alderman_votes table to the variable votes_dataframe
votes_dataframe = dataset.dataframes['alderman_votes']

# Use the pandas shape property
# Get rows/columns size for the `votes_dataframe` dataframe
pp.pprint(votes_dataframe.shape)
</code></pre>

<pre><code>(10850, 5)
</code></pre>
<pre><code class="python"># Use the pandas head function
# Print the first 3 rows of the `votes_dataframe` dataframe
pp.pprint(votes_dataframe.head(3))
</code></pre>

<pre><code>                alderman vote  ward       date       record
0          Manuel Flores    N     1 2006-07-26  SO2006-3086
1  Madeline L. Haithcock    N     2 2006-07-26  SO2006-3086
2     Dorothy J. Tillman    N     3 2006-07-26  SO2006-3086
</code></pre>
<h3 id="working-with-multiple-datasets">Working with multiple datasets<a class="headerlink" href="#working-with-multiple-datasets" title="Permanent link">&para;</a></h3>
<pre><code class="python">import datadotworld as dw

# Loaded two datasets
int_dataset = dw.load_dataset('https://data.world/jonloyens/intermediate-data-world')
fipsCodes_dataset = dw.load_dataset('https://data.world/uscensusbureau/fips-state-codes')
</code></pre>

<pre><code class="python"># Create two dataframes:
# police_shootings from the 'fatal_police_shootings_data' table of int_dataset and
# state_abbrvs, from the 'statesfipscodes' table of fipsCodes_dataset
police_shootings = int_dataset.dataframes['fatal_police_shootings_data']
state_abbrvs = fipsCodes_dataset.dataframes['statesfipscodes']

# Merge the two datasets together
# on the state and stusab fields
# Assign to a merged_dataframe variable
merged_dataframe = police_shootings.merge(state_abbrvs,
                                          how = 'left',
                                          left_on = 'state',
                                          right_on='stusab')

# Add a 'citystate' column to the merged_dataframe dataframe,
# populating it with the concatinated values from the 'city' and 'state_name' columns,
# separated by ', '
merged_dataframe[&quot;citystate&quot;] = merged_dataframe[&quot;city&quot;] + \
                                &quot;, &quot; + merged_dataframe[&quot;state_name&quot;]

## Print head of merged_dataframe
pp.pprint(merged_dataframe.head(5))
</code></pre>

<pre><code>   id                name        date   manner_of_death       armed   age  \
0   3          Tim Elliot  2015-01-02              shot         gun  53.0   
1   4    Lewis Lee Lembke  2015-01-02              shot         gun  47.0   
2   5  John Paul Quintero  2015-01-03  shot and Tasered     unarmed  23.0   
3   8     Matthew Hoffman  2015-01-04              shot  toy weapon  32.0   
4   9   Michael Rodriguez  2015-01-04              shot    nail gun  39.0

  gender race           city state  signs_of_mental_illness threat_level  \
0      M    A        Shelton    WA                     True       attack   
1      M    W          Aloha    OR                    False       attack   
2      M    H        Wichita    KS                    False        other   
3      M    W  San Francisco    CA                     True       attack   
4      M    H          Evans    CO                    False       attack

          flee  body_camera  state_fips stusab  state_name  statens  \
0  Not fleeing        False          53     WA  Washington  1779804   
1  Not fleeing        False          41     OR      Oregon  1155107   
2  Not fleeing        False          20     KS      Kansas   481813   
3  Not fleeing        False           6     CA  California  1779778   
4  Not fleeing        False           8     CO    Colorado  1779779

                   citystate  
0        Shelton, Washington  
1              Aloha, Oregon  
2            Wichita, Kansas  
3  San Francisco, California  
4            Evans, Colorado
</code></pre>
<h3 id="querying-with-dataworld">Querying with data.world<a class="headerlink" href="#querying-with-dataworld" title="Permanent link">&para;</a></h3>
<p>Another way to pull data in from data.world is to use the <code>query()</code> method to use SQL or SPARQL to query one or more datasets. Check out the full dwSQL <a href="https://docs.data.world/tutorials/dwsql/">documentation</a>.</p>
<h4 id="sql-querying-a-table">SQL: Querying a table<a class="headerlink" href="#sql-querying-a-table" title="Permanent link">&para;</a></h4>
<pre><code class="python">import datadotworld as dw

# Run a SQL query
# Select all rows from the `unhcr_all` table where `Year` equals 2010
# Assign the query string to a `sql_query` variable
sql_query = &quot;SELECT * FROM `unhcr_all` WHERE Year = 2010&quot;

# Use the `query` method of the datadotworld module
# Run the `sql_query`
# Assign the results to a `query2010` variable
query2010 = dw.query('https://data.world/agriculture/national-farmers-markets', sql_query)

# Use the dataframe property of the resulting query
# Create a dataframe variable named `unhcr2010`
unhcr2010 = query2010.dataframe

# Print the first 5 rows using the head method
pp.pprint(unhcr2010.head(5))
</code></pre>

<h4 id="sql-query-multiple-tables-join">SQL: Query multiple tables (join)<a class="headerlink" href="#sql-query-multiple-tables-join" title="Permanent link">&para;</a></h4>
<p>Write queries against multiple tables within a single dataset or across many datasets! </p>
<pre><code class="python">import datadotworld as dw

# Run a SQL query
# Select state, the count of farmers markets (fmid),
# and average obesity rate 
# from agriculture.`national-farmers-markets`.export,
# LEFT JOINED against health.`obesity-by-state-2014`
# adult_obese on state and location
sql_query = &quot;SELECT state, count(fmid) as count, Avg(obesity.Value) as obesityAvg FROM Export LEFT JOIN health.`obesity-by-state-2014`.`adult_obese` as obesity ON state = obesity.location GROUP BY state ORDER BY count desc&quot;

# Use the `query` method of the datadotworld module
# Run the `sql_query` against the `https://data.world/agriculture/national-farmers-markets` dataset
# Assign the results to a `queryResults` variable
queryResults = dw.query('https://data.world/agriculture/national-farmers-markets', \
                        sql_query)

# Use the dataframes property of the resulting query
# Create a dataframe variable named `stateStats`
stateStats = queryResults.dataframe
</code></pre>

<pre><code class="python">import matplotlib.pyplot as plt

# Plot the stateStats results using state as the x-axis
stateStats.plot(x='state')

plt.show()
</code></pre>

<p><img alt="" src="../img/intro_to_data_world/output_21_0.png" /></p>
<h4 id="sparql-querying-linked-data">SPARQL: Querying linked data<a class="headerlink" href="#sparql-querying-linked-data" title="Permanent link">&para;</a></h4>
<p>Behind the scenes, data.world is converting all tabular data files into linked data using Semantic Web technologies. This allows to upload any tabular format, like xlsx, csv, tsv or json, and instantly be able to query and join them without issue. SQL is great for this, but SPARQL - which is the query language for linked data - can be more robust and flexible than SQL, allowing for more complex queries.</p>
<p>Check out the full SPARQL <a href="https://docs.data.world/documentation/api/sparql.html">documentation</a>.</p>
<pre><code class="python">import datadotworld as dw

# A SPARQL query assigned to the `sparql_query` variable: 
sparql_query = &quot;PREFIX GOT: &lt;https://tutorial.linked.data.world/d/sparqltutorial/&gt; SELECT ?FName ?LName WHERE {?person GOT:col-got-house \&quot;Stark\&quot; . ?person GOT:col-got-fname ?FName . ?person GOT:col-got-lname ?LName .}&quot;

# Use the pre-defined SPARQL query
# Query dataset http://data.world/tutorial/sparqltutorial and
# return the results to a queryResults variable
queryResults = dw.query('http://data.world/tutorial/sparqltutorial', \
                        sparql_query, query_type='sparql')

# Use the dataframe property of the resulting query
# Create a dataframe variable named `houseStark`
houseStark = queryResults.dataframe

# Use pp.pprint() to print the dataframe to the screen
pp.pprint(houseStark)
</code></pre>

<pre><code>    FName  LName
0    Robb  Stark
1     Jon   Snow
2   Sansa  Stark
3    Arya  Stark
4    Bran  Stark
5  Rickon  Stark
</code></pre>
<h3 id="wrap-up">Wrap up<a class="headerlink" href="#wrap-up" title="Permanent link">&para;</a></h3>
<pre><code class="python">import datadotworld as dw
# Import the sys module
import sys

# Import a dataset
refugee_dataset = dw.load_dataset('nrippner/refugee-host-nations')

# Get the size of the dataset:
sys.getsizeof(refugee_dataset)
</code></pre>

<pre><code>56
</code></pre>
<pre><code class="python"># List all of the data files:
dataframes = refugee_dataset.dataframes
for df in dataframes:
    pp.pprint(df)
</code></pre>

<pre><code>'refugees2011_15'
'refugees_all_years'
'refugees_per_capita'
'unhcr_2015'
'unhcr_all'
'worldbank_data_dict'
'worldbank_indicators'
</code></pre>
<pre><code class="python"># Print all of the files in a dataset:
resources = refugee_dataset.describe()['resources']
pp.pprint('name:')
for r in resources:
    pp.pprint(r['name'])
pp.pprint('\ntype of file:')
for r in resources:
    pp.pprint(r['format'])
</code></pre>

<pre><code>'name:'
'refugees2011_15'
'refugees_all_years'
'refugees_per_capita'
'unhcr_2015'
'unhcr_all'
'worldbank_data_dict'
'worldbank_indicators'
'original/Refugees.ipynb'
'original/refs.py'
'original/refugees2011-15.csv'
'original/refugees_all_years.csv'
'original/refugees_per_capita.csv'
'original/unhcr_2015.csv'
'original/unhcr_all.csv'
'original/worldbank_data_dict.csv'
'original/worldbank_indicators.csv'
'\ntype of file:'
'csv'
'csv'
'csv'
'csv'
'csv'
'csv'
'csv'
'ipynb'
'py'
'csv'
'csv'
'csv'
'csv'
'csv'
'csv'
'csv'
</code></pre>
<h3 id="advanced-sdk-functionality">Advanced SDK Functionality<a class="headerlink" href="#advanced-sdk-functionality" title="Permanent link">&para;</a></h3>
<p>The data.world Python SDK includes a variety of API wrappers, available via the <code>ApiClient</code> class, to create, replace, update, and delete a dataset. In this section, we walk through a few common tasks:</p>
<ul>
<li>Use <code>api_client()</code> to get an instance of the <code>ApiClient</code></li>
<li>Create a dataset</li>
<li>Add a file from a dataframe: we write to a local csv and the upload the file</li>
<li>Add a file from a source URL: this is an easy way to add external data to the dataset and keep it up to date. We use a file from GitHub as an example, but we can use any URL source that points to a file.</li>
<li>Sync the dataset: this simple call reloads any files with a source URL, to ensure the latest version.</li>
<li>Update the dataset: after creating a dataset, use <code>update_dataset</code> to change attiributes like description, summary or tags.</li>
</ul>
<p>Use <code>help(api_client)</code> to learn more about each available function or see the full <a href="https://docs.data.world/documentation/api/">data.world API documentation</a>.</p>
<h4 id="open-the-api">Open the API<a class="headerlink" href="#open-the-api" title="Permanent link">&para;</a></h4>
<pre><code class="python">import datadotworld as dw

# Create an instance of the ApiClient using `api_client()`
api_client = dw.api_client()

# See api_client documentation
help(api_client)
</code></pre>

<pre><code>Help on RestApiClient in module datadotworld.client.api object:

class RestApiClient(builtins.object)
 |  REST API client
 |  
 |  Parameters
 |  ----------
 |  profile : str, optional
 |      Name of the configuration profile to use
 |  
 |  Methods defined here:
 |  
 |  __init__(self, config)
 |      Initialize self.  See help(type(self)) for accurate signature.
 |  
 |  add_files_via_url(self, dataset_key, files={})
 |      Add or update dataset files linked to source URLs
 |      
 |      Parameters
 |      ----------
 |      dataset_key : str
 |          Dataset identifier, in the form of owner/id
 |      files : dict
 |          File names and source URLs to add or update
 |      
 |      Raises
 |      ------
 |      RestApiException
 |          If a server error occurs
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; import datadotworld as dw
 |      &gt;&gt;&gt; url = 'http://www.acme.inc/example.csv'
 |      &gt;&gt;&gt; api_client = dw.api_client()
 |      &gt;&gt;&gt; api_client.add_files_via_url(
 |      ...    'username/test-dataset',
 |      ...    {'example.csv': url})  # doctest: +SKIP
 |  
 |  create_dataset(self, owner_id, **kwargs)
 |      Create a new dataset
 |      
 |      Parameters
 |      ----------
 |      owner_id : str
 |          Username of the owner of the new dataset
 |      title : str
 |          Dataset title (will be used to generate dataset id on creation)
 |      description : str, optional
 |          Dataset description
 |      summary : str, optional
 |          Dataset summary markdown
 |      tags : list, optional
 |          Dataset tags
 |      license : {'Public Domain', 'PDDL', 'CC-0', 'CC-BY', 'ODC-BY',
 |                 'CC-BY-SA', 'ODC-ODbL', 'CC BY-NC', 'CC BY-NC-SA', 'Other'}
 |          Dataset license
 |      visibility : {'OPEN', 'PRIVATE'}
 |          Dataset visibility
 |      files : dict, optional
 |          File names and source URLs
 |      
 |      Returns
 |      -------
 |      str
 |          Newly created dataset key
 |      
 |      Raises
 |      ------
 |      RestApiException
 |          If a server error occurs
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; import datadotworld as dw
 |      &gt;&gt;&gt; api_client = dw.api_client()
 |      &gt;&gt;&gt; api_client.create_dataset(
 |      ...     'username', title='Test dataset', visibility='PRIVATE',
 |      ...     license='Public Domain')  # doctest: +SKIP
 |  
 |  delete_files(self, dataset_key, names)
 |      Delete dataset file(s)
 |      
 |      Parameters
 |      ----------
 |      dataset_key : str
 |          Dataset identifier, in the form of owner/id
 |      names : list of str
 |          The list of names for files to be deleted
 |      
 |      Raises
 |      ------
 |      RestApiException
 |          If a server error occurs
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; import datadotworld as dw
 |      &gt;&gt;&gt; api_client = dw.api_client()
 |      &gt;&gt;&gt; api_client.delete_files(
 |      ...     'username/test-dataset', ['example.csv'])  # doctest: +SKIP
 |  
 |  download_datapackage(self, dataset_key, dest_dir)
 |      Download and unzip a dataset's datapackage
 |      
 |      Parameters
 |      ----------
 |      dataset_key : str
 |          Dataset identifier, in the form of owner/id
 |      dest_dir : str or path
 |          Directory under which datapackage should be saved
 |      
 |      Returns
 |      -------
 |      path
 |          Location of the datapackage descriptor (datapackage.json) in the
 |          local filesystem
 |      
 |      Raises
 |      ------
 |      RestApiException
 |          If a server error occurs
 |      
 |      Examples
 |      &gt;&gt;&gt; import datadotworld as dw
 |      &gt;&gt;&gt; api_client = dw.api_client()
 |      &gt;&gt;&gt; datapackage_descriptor = api_client.download_datapackage(
 |      ...     'jonloyens/an-intro-to-dataworld-dataset', '/tmp/test')
 |      &gt;&gt;&gt; datapackage_descriptor
 |      '/tmp/test/datapackage.json'
 |  
 |  get_dataset(self, dataset_key)
 |      Retrieve an existing dataset definition
 |      
 |      This method retrieves metadata about an existing
 |      
 |      Parameters
 |      ----------
 |      dataset_key : str
 |          Dataset identifier, in the form of owner/id
 |      
 |      Returns
 |      -------
 |      dict
 |          Dataset definition, with all attributes
 |      
 |      Raises
 |      ------
 |      RestApiException
 |          If a server error occurs
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; import datadotworld as dw
 |      &gt;&gt;&gt; api_client = dw.api_client()
 |      &gt;&gt;&gt; intro_dataset = api_client.get_dataset(
 |      ...     'jonloyens/an-intro-to-dataworld-dataset')
 |      &gt;&gt;&gt; intro_dataset['title']
 |      'An Intro to data.world Dataset'
 |  
 |  replace_dataset(self, dataset_key, **kwargs)
 |      Replace an existing dataset
 |      
 |      *This method will completely overwrite an existing dataset.*
 |      
 |      Parameters
 |      ----------
 |      description : str, optional
 |          Dataset description
 |      summary : str, optional
 |          Dataset summary markdown
 |      tags : list, optional
 |          Dataset tags
 |      license : {'Public Domain', 'PDDL', 'CC-0', 'CC-BY', 'ODC-BY',
 |                 'CC-BY-SA', 'ODC-ODbL', 'CC BY-NC', 'CC BY-NC-SA', 'Other'}
 |          Dataset license
 |      visibility : {'OPEN', 'PRIVATE'}
 |          Dataset visibility
 |      files : dict, optional
 |          File names and source URLs to add or update
 |      
 |      Raises
 |      ------
 |      RestApiException
 |          If a server error occurs
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; import datadotworld as dw
 |      &gt;&gt;&gt; api_client = dw.api_client()
 |      &gt;&gt;&gt; api_client.replace_dataset(
 |      ...    'username/test-dataset',
 |      ...    visibility='PRIVATE', license='Public Domain',
 |      ...    description='A better description')  # doctest: +SKIP
 |  
 |  sync_files(self, dataset_key)
 |      Trigger synchronization process to update all dataset files linked to
 |      source URLs.
 |      
 |      Parameters
 |      ----------
 |      dataset_key : str
 |          Dataset identifier, in the form of owner/id
 |      
 |      Raises
 |      ------
 |      RestApiException
 |          If a server error occurs
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; import datadotworld as dw
 |      &gt;&gt;&gt; api_client = dw.api_client()
 |      &gt;&gt;&gt; api_client.sync_files('username/test-dataset')  # doctest: +SKIP
 |  
 |  update_dataset(self, dataset_key, **kwargs)
 |      Update an existing dataset
 |      
 |      Parameters
 |      ----------
 |      description : str, optional
 |          Dataset description
 |      summary : str, optional
 |          Dataset summary markdown
 |      tags : list, optional
 |          Dataset tags
 |      license : {'Public Domain', 'PDDL', 'CC-0', 'CC-BY', 'ODC-BY',
 |                 'CC-BY-SA', 'ODC-ODbL', 'CC BY-NC', 'CC BY-NC-SA', 'Other'}
 |          Dataset license
 |      visibility : {'OPEN', 'PRIVATE'}, optional
 |          Dataset visibility
 |      files : dict, optional
 |          File names and source URLs to add or update
 |      
 |      Raises
 |      ------
 |      RestApiException
 |          If a server error occurs
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; import datadotworld as dw
 |      &gt;&gt;&gt; api_client = dw.api_client()
 |      &gt;&gt;&gt; api_client.update_dataset(
 |      ...    'username/test-dataset',
 |      ...    tags=['demo', 'datadotworld'])  # doctest: +SKIP
 |  
 |  upload_files(self, dataset_key, files)
 |      Upload dataset files
 |      
 |      Parameters
 |      ----------
 |      dataset_key : str
 |          Dataset identifier, in the form of owner/id
 |      files : list of str
 |          The list of names/paths for files stored in the local filesystem
 |      
 |      Raises
 |      ------
 |      RestApiException
 |          If a server error occurs
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; import datadotworld as dw
 |      &gt;&gt;&gt; api_client = dw.api_client()
 |      &gt;&gt;&gt; api_client.upload_files(
 |      ...     'username/test-dataset',
 |      ...     ['/my/local/example.csv'])  # doctest: +SKIP
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors defined here:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
</code></pre>
<h4 id="create-a-dataset-using-create_dataset-method">Create a dataset using create_dataset method<a class="headerlink" href="#create-a-dataset-using-create_dataset-method" title="Permanent link">&para;</a></h4>
<p><code>api_client.create_dataset(owner_id="&lt;YOUR_USERNAME&gt;", title="&lt;DATASET_TITLE&gt;", visibility='PRIVATE')</code></p>
<pre><code class="python">import datadotworld as dw

# Replace the &lt; &gt; items with your username and desired dataset title
# Visibility can be changed to 'OPEN' if you choose
api_client.create_dataset(owner_id=&quot;ugo&quot;, title=&quot;intermediate-data-world&quot;, visibility='OPEN')
</code></pre>

<pre><code>'https://data.world/ugo/intermediate-data-world'
</code></pre>
<h4 id="write-a-dataframe-to-a-local-file-and-upload-to-dataset">Write a dataframe to a local file and upload to dataset<a class="headerlink" href="#write-a-dataframe-to-a-local-file-and-upload-to-dataset" title="Permanent link">&para;</a></h4>
<p>Add file to the dataset using upload_files(). Replace the &lt; &gt; items with the dataset values.</p>
<p><code>api_client.upload_files('&lt;YOUR_USERNAME&gt;/&lt;DATASET_TITLE&gt;',['police_shootings.csv'])</code></p>
<pre><code class="python">import os

cwd = os.getcwd()
#print(cwd)
</code></pre>

<pre><code class="python">import datadotworld as dw

# Create a dataframe
police_shootings = dw.load_dataset('https://data.world/jonloyens/intermediate-data-world').dataframes['fatal_police_shootings_data']

# Write dataframe to local csv using pandas to_csv() method
# in the current working directory (cwd)
police_shootings.to_csv('police_shootings.csv', encoding='utf-8')
</code></pre>

<p>Check the current working directory.</p>
<h4 id="update-dataset">Update dataset<a class="headerlink" href="#update-dataset" title="Permanent link">&para;</a></h4>
<p>Add a file from an external source URL. In this example we use GitHub. <br />
Replace the &lt; &gt; items with the dataset values</p>
<p><code>api_client.add_files_via_url('&lt;YOUR_USERNAME&gt;/&lt;DATASET_TITLE&gt;',{'shootings_of_police.csv': 'https://github.com/fivethirtyeight/data/blob/master/police-deaths/all_data.csv’})</code></p>
<p>For files added with <code>add_files_via_url</code>, fetch the latest version using the <code>sync()</code> method:</p>
<p><code>api_client.sync_files('&lt;YOUR_USERNAME&gt;/&lt;DATASET_TITLE&gt;')</code></p>
<p>Use the <code>update_dataset()</code> method to update the metadata after dataset creation:</p>
<p><code>api_client.update_dataset('&lt;YOUR_USERNAME&gt;/&lt;DATASET_TITLE&gt;', description='Dataset created to test out the python SDK functionality.', tags=['test', 'datacamp'])</code></p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../Python+And+Excel/" class="btn btn-neutral float-right" title="Python and Excel">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../Exploratory Data Analysis/" class="btn btn-neutral" title="Exploratory Data Analysis"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>© Ugo Sparks</p>
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../Exploratory Data Analysis/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../Python+And+Excel/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../js/theme.js"></script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
      <script src="../mathjaxhelper.js"></script>

</body>
</html>
